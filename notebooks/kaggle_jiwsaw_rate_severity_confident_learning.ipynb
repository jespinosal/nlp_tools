{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_jiwsaw_rate_severity_confident_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADx-3owccopE",
        "outputId": "1db55205-254c-4344-9692-fd37ecb50b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleanlab\n",
            "  Downloading cleanlab-1.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (4.62.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.1.0)\n",
            "Installing collected packages: cleanlab\n",
            "Successfully installed cleanlab-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cleanlab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import cleanlab\n",
        "from cleanlab.classification import LearningWithNoisyLabels\n",
        "from tqdm import tqdm\n",
        "import plotly.express as px\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JznRnbyEctnj",
        "outputId": "56e7ee0f-bbfa-4634-a3a3-f3c065be0b39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_drive = '/content/drive'\n",
        "path_data = os.path.join(path_drive, 'MyDrive','Colab\\ Notebooks', 'kaggle', 'data')\n",
        "drive.mount(path_drive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35CD6jctcyKo",
        "outputId": "7e5a97ee-f7f6-4a0b-8603-8aac3c9301d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp {path_data} -r ./\n",
        "!git clone https://github.com/jespinosal/nlp_tools.git\n",
        "%cd nlp_tools/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojKFDaVzdREa",
        "outputId": "7b62cefe-1462-4f5e-c987-e8a5afaf96ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp_tools'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 71 (delta 37), reused 58 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n",
            "/content/nlp_tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.confident_learning import get_k_fold_class_probs, get_noisy_labels\n",
        "from parser.preprocessing import clean_text, stopwords\n",
        "from nltk.corpus import stopwords as stopwords_set\n",
        "from utils.data_partition import set_cv_dataset_partitions\n",
        "from models.confident_learning import get_k_fold_class_probs, get_noisy_labels"
      ],
      "metadata": {
        "id": "INnb17wgdUXv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA_PATH = \"/content/data/jigsaw-toxic-comment-classification-challenge/train.csv\"\n",
        "VALID_DATA_PATH = \"/content/data/jigsaw-toxic-severity-rating/validation_data.csv\""
      ],
      "metadata": {
        "id": "hPDmylRbmoIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords_set.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "df_train = pd.read_csv(TRAIN_DATA_PATH)\n",
        "df_train = df_train.reset_index().rename(columns={'index':'comment_id'}) \n",
        "df_validation_data = pd.read_csv(VALID_DATA_PATH)\n",
        "\n",
        "unrelevant_words = ['wiki','wikipedia','page']\n",
        "\n",
        "df_train['comment_text'] = df_train['comment_text'].apply(lambda x: ''.join([w for w in clean_text(x) if w not in unrelevant_words]))\n",
        "df_train['comment_text'] = df_train['comment_text'].apply(lambda x: ''.join([w for w in stopwords(x,stop_words)]))\n",
        "df_train['comment_text'] = df_train['comment_text'].apply(lambda x: ''.join([w for w in lemmatizer.lemmatize(x)]))\n",
        "\n",
        "df_validation_data['less_toxic'] = df_validation_data['less_toxic'].apply(lambda x: ''.join([w for w in clean_text(x) if w not in unrelevant_words]))\n",
        "df_validation_data['less_toxic'] = df_validation_data['less_toxic'].apply(lambda x: ''.join([w for w in stopwords(x,stop_words)]))\n",
        "df_validation_data['less_toxic'] = df_validation_data['less_toxic'].apply(lambda x: ''.join([w for w in lemmatizer.lemmatize(x)]))\n",
        "\n",
        "df_validation_data['more_toxic'] = df_validation_data['more_toxic'].apply(lambda x: ''.join([w for w in clean_text(x) if w not in unrelevant_words]))\n",
        "df_validation_data['more_toxic'] = df_validation_data['more_toxic'].apply(lambda x: ''.join([w for w in stopwords(x,stop_words)]))\n",
        "df_validation_data['more_toxic'] = df_validation_data['more_toxic'].apply(lambda x: ''.join([w for w in lemmatizer.lemmatize(x)]))\n",
        "\n",
        "\n",
        "# Create a score that messure how much toxic is a comment\n",
        "cat_mtpl = {'obscene': 0.10, 'toxic': 0.20, 'threat': 0.5, \n",
        "            'insult': 0.62, 'severe_toxic': 0.7, 'identity_hate': 1}\n",
        "\n",
        "for category in cat_mtpl:\n",
        "    df_train[category] = df_train[category] * cat_mtpl[category]\n",
        "\n",
        "df_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n",
        "\n",
        "\n",
        "#Balance the clases\n",
        "n_samples_toxic = len(df_train[df_train['score'] != 0])\n",
        "n_samples_normal = len(df_train) - n_samples_toxic\n",
        "\n",
        "idx_to_drop = df_train[df_train['score'] == 0].index[n_samples_toxic//5:]\n",
        "df_train = df_train.drop(idx_to_drop)\n",
        "\n",
        "print(f'Reduced number of neutral text samples from {n_samples_normal} to {n_samples_toxic//5}.')\n",
        "print(f'Total number of training samples: {len(df_train)}')\n",
        "\n",
        "#Feature engineering for creating \n",
        "df_tragets = pd.DataFrame(pd.unique(df_train['score'].values), columns=['target_value']).sort_values(by='target_value', ascending = True).reset_index(drop=True)\n",
        "THRESHOLD = df_tragets['target_value'].quantile(q=0.2)\n",
        "df_train['sentiment'] = df_train['score'].map(lambda x: 0 if x < THRESHOLD else 1 if x < THRESHOLD*2 else 2 if x < THRESHOLD*3 else 3 if x < THRESHOLD*4 else 4)\n",
        "df_train = df_train.loc[df_train.comment_text.str.len() >3,]\n",
        "df_train = df_train[['comment_text','sentiment', 'comment_id']].reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE2wKpLQexDW",
        "outputId": "6661b6c1-b1e8-4818-d9db-68dfb8c13519"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced number of neutral text samples from 143346 to 3245.\n",
            "Total number of training samples: 19470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model training with noise"
      ],
      "metadata": {
        "id": "C8tgTjQPoRVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_vect = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=10500) \n",
        "X = tf_idf_vect.fit_transform(df_train['comment_text'])\n",
        "model = MultinomialNB()\n",
        "model.fit(X, df_train['sentiment'])\n",
        "# Validate\n",
        "X_less_toxic = tf_idf_vect.transform(df_validation_data['less_toxic'])\n",
        "X_more_toxic = tf_idf_vect.transform(df_validation_data['more_toxic'])\n",
        "p1 = model.predict_proba(X_less_toxic)\n",
        "p2 = model.predict_proba(X_more_toxic)\n",
        "print(f\"Accuracy validation dataset: {(p1[:, 1] < p2[:, 1]).mean()}\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7FF_o91oDWD",
        "outputId": "96cc3b29-53bf-4a3a-d130-00abf3a45aca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy validation dataset: 0.6330543377175502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model confident learning default implementation"
      ],
      "metadata": {
        "id": "8DqQP3Dbo69K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_vect = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=5000, norm='l2') # Library fails when vector features are poor\n",
        "\n",
        "X = tf_idf_vect.fit_transform(df_train['comment_text'])\n",
        "base_model = MultinomialNB()\n",
        "model = LearningWithNoisyLabels(clf=base_model,\n",
        "                                seed=100,\n",
        "                                cv_n_folds=10,\n",
        "                                prune_method='both',\n",
        "                                converge_latent_estimates=False,\n",
        "                                pulearning=None,\n",
        "                                n_jobs=2)\n",
        "model.fit(X=X, s=df_train['sentiment'].values) # noise_mask, sample_weight \n",
        "\n",
        "# Validate\n",
        "X_less_toxic = tf_idf_vect.transform(df_validation_data['less_toxic'])\n",
        "X_more_toxic = tf_idf_vect.transform(df_validation_data['more_toxic'])\n",
        "p1 = model.predict_proba(X_less_toxic)\n",
        "p2 = model.predict_proba(X_more_toxic)\n",
        "print(f\"Accuracy validation dataset: {(p1[:, 1] < p2[:, 1]).mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJtZZzROpR35",
        "outputId": "6a2b32f6-34e1-45d1-d8df-2e7952795c85"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy validation dataset: 0.6194366945662283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model confident learning custom implementation"
      ],
      "metadata": {
        "id": "-CEurK8UpS_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds=10\n",
        "feature_transformer = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=10500)\n",
        "classifier = MultinomialNB\n",
        "df_train_ = set_cv_dataset_partitions(df=df_train, stratify_column='sentiment', k_folds=folds, seed=100)\n",
        "df_train_ = get_k_fold_class_probs(df=df_train_,transformation=feature_transformer, baseline_model=classifier, k_folds=10)\n",
        "multi_label = False\n",
        "pyx= np.array(df_train_['predictions_probs'].to_list()) #  #This is the probability distribution of probabilities for each of the N examples x. \n",
        "s = df_train['sentiment'].values # A discrete vector of labels, s, which may contain mislabeling. “s”\n",
        "cj_only_bool_mask, label_errors_idx_sorted, label_errors_idx = get_noisy_labels(pyx=pyx, s=s, multi_label=multi_label, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g89SFB4paSg",
        "outputId": "65938f4d-d0bf-41b9-896a-a976bcbb7cdf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total found error indices 6779 like [ 6 15 27 42 55] ..\n",
            "Total components on the matrix 19462\n",
            "confident join marix [[8675 1171    9    1 1562]\n",
            " [2020 3088   34    0  653]\n",
            " [ 355 1369   39    0  123]\n",
            " [  47  257   17    0   11]\n",
            " [   1   29    0    0    1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('IDs with errors filtered', len(label_errors_idx))\n",
        "print('IDs with errors', len(label_errors_idx_sorted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JtrLMypw0vi",
        "outputId": "577b2d78-ccb4-44e3-c51a-35c5fb76061e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDs with errors filtered 4778\n",
            "IDs with errors 6779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with noise\n",
        "# Note: index_id is used such as noise dataset reference and commend_id such as \n",
        "# Optimize the threshold filtering the top_k noisy labels\n",
        "top_k_max = len(label_errors_idx_sorted)\n",
        "steps = 10\n",
        "noise_top_k = list(range(1, top_k_max, steps))\n",
        "accuracy_list = []\n",
        "tf_idf_vect = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=10500)\n",
        "#tf_idf_vect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3) )\n",
        "tf_idf_vect.fit(df_train_['comment_text'])\n",
        "X_less_toxic = tf_idf_vect.transform(df_validation_data['less_toxic'])\n",
        "X_more_toxic = tf_idf_vect.transform(df_validation_data['more_toxic'])\n",
        "for top_k in tqdm(noise_top_k):\n",
        "    index_to_filter = df_train_.index_id.isin(label_errors_idx_sorted[0:top_k])\n",
        "    commend_id_filter = df_train_.loc[index_to_filter,'comment_id']\n",
        "    df_train_filtered = df_train_.loc[~df_train_.comment_id.isin(commend_id_filter),:]\n",
        "    X = tf_idf_vect.transform(df_train_filtered['comment_text'])\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X, df_train_filtered['sentiment'])\n",
        "    # Validate\n",
        "    p1 = model.predict_proba(X_less_toxic)\n",
        "    p2 = model.predict_proba(X_more_toxic)\n",
        "    accuracy_val = (p1[:, 1] < p2[:, 1]).mean()\n",
        "    accuracy_list.append(accuracy_val)\n",
        "\n",
        "print(f\"Accuracy validation dataset mean: {np.mean(accuracy_list)}\")\n",
        "print(f\"Accuracy validation dataset max: {np.max(accuracy_list)} for {noise_top_k[np.argmax(accuracy_list)]} threshold \")\n",
        "fig = px.scatter(x=noise_top_k, y=accuracy_list, color=accuracy_list) # todo coloour the label\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "W2wnRiA7uZXN",
        "outputId": "c0eaad3e-5891-4071-88c2-912ce67386df"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 678/678 [05:32<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy validation dataset mean: 0.628541870701071\n",
            "Accuracy validation dataset max: 0.634582170851601 for 101 threshold \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"103ab8be-d62b-49d4-b7d1-c3e708f0fd7b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"103ab8be-d62b-49d4-b7d1-c3e708f0fd7b\")) {                    Plotly.newPlot(                        \"103ab8be-d62b-49d4-b7d1-c3e708f0fd7b\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>color=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.6326225587883619,0.6330543377175502,0.6330875514813339,0.6329546964261991,0.6329879101899827,0.6329214826624153,0.6331207652451176,0.6334529028829547,0.6335857579380896,0.6338182542845755,0.634582170851601,0.6342168194499801,0.6337518267570081,0.6332536203002525,0.6333532615916035,0.6331539790089012,0.6334529028829547,0.6330875514813339,0.6332868340640362,0.6337518267570081,0.6335857579380896,0.6330875514813339,0.6329214826624153,0.6324897037332271,0.6328882688986316,0.6328218413710641,0.6326889863159293,0.6323900624418759,0.6324564899694434,0.6324564899694434,0.6326225587883619,0.6323900624418759,0.6326889863159293,0.6328218413710641,0.6325893450245782,0.6323236349143085,0.6327886276072805,0.6327886276072805,0.632722200079713,0.6325561312607945,0.6325561312607945,0.6326889863159293,0.6326557725521456,0.6323568486780922,0.632722200079713,0.6327554138434968,0.6327886276072805,0.6326225587883619,0.6326225587883619,0.6323568486780922,0.6322239936229573,0.6328218413710641,0.6327554138434968,0.6324897037332271,0.6327554138434968,0.6325893450245782,0.6330211239537664,0.6328550551348479,0.6326225587883619,0.6326557725521456,0.6326557725521456,0.6327554138434968,0.6322572073867411,0.63215756609539,0.632024711040255,0.6318918559851202,0.631925069748904,0.6314268632921483,0.6313604357645809,0.6313272220007972,0.631460077055932,0.6313272220007972,0.6312607944732297,0.6320579248040388,0.6322572073867411,0.6322572073867411,0.6323568486780922,0.6319582835126877,0.6315929321110668,0.6318918559851202,0.6312607944732297,0.63099508436296,0.630762588016474,0.6312607944732297,0.6310282981267438,0.6309618705991763,0.6311279394180949,0.6308290155440415,0.6311611531818786,0.6308622293078252,0.6308954430716088,0.6311279394180949,0.631227580709446,0.6314268632921483,0.6316593596386343,0.6316593596386343,0.6313936495283645,0.6311943669456623,0.6310282981267438,0.6306629467251229,0.63099508436296,0.6307293742526903,0.6301647402683672,0.6302643815597183,0.6306629467251229,0.6305633054337717,0.6306297329613392,0.6305965191975554,0.6303308090872858,0.629732961339179,0.6296001062840441,0.6296997475753953,0.6295668925202604,0.6295336787564767,0.629732961339179,0.6298326026305301,0.6298990301580976,0.6296997475753953,0.6296001062840441,0.6296997475753953,0.6297661751029626,0.6295336787564767,0.6296665338116115,0.6296001062840441,0.6297661751029626,0.6296001062840441,0.6296333200478278,0.6298326026305301,0.6295668925202604,0.6296997475753953,0.629732961339179,0.6298990301580976,0.6295668925202604,0.6292015411186396,0.629500464992693,0.629500464992693,0.629267968646207,0.6294672512289092,0.629500464992693,0.6293676099375581,0.6294672512289092,0.6292015411186396,0.6296001062840441,0.6291683273548558,0.6290686860635047,0.6292015411186396,0.6294008237013419,0.629500464992693,0.6293343961737744,0.6294672512289092,0.629500464992693,0.6294672512289092,0.6296333200478278,0.6295668925202604,0.6293343961737744,0.6294672512289092,0.6291351135910721,0.6289690447721535,0.6291351135910721,0.6295336787564767,0.6296665338116115,0.6293343961737744,0.6291018998272885,0.6292015411186396,0.629267968646207,0.6296665338116115,0.6298326026305301,0.6299654576856649,0.6294672512289092,0.629732961339179,0.6302311677959347,0.6295336787564767,0.6296333200478278,0.6294672512289092,0.6295336787564767,0.6296665338116115,0.6295336787564767,0.6294340374651255,0.6293676099375581,0.6293011824099907,0.6296001062840441,0.6294672512289092,0.6296665338116115,0.6298658163943138,0.6297993888667464,0.629267968646207,0.6288361897170187,0.6288694034808024,0.6287697621894514,0.6292015411186396,0.6295668925202604,0.6290022585359373,0.628570479606749,0.6286701208981001,0.6285040520791816,0.628337983260263,0.6282715557326957,0.6285040520791816,0.6287365484256676,0.629035472299721,0.6291351135910721,0.6290686860635047,0.6291018998272885,0.629035472299721,0.6290686860635047,0.629267968646207,0.6291351135910721,0.6291018998272885,0.6287033346618839,0.628570479606749,0.6285372658429653,0.628802975953235,0.6286701208981001,0.6287033346618839,0.6289690447721535,0.6289358310083699,0.6289026172445862,0.6286036933705328,0.628802975953235,0.6286369071343164,0.6288694034808024,0.6291351135910721,0.6292015411186396,0.6290686860635047,0.628570479606749,0.6288694034808024,0.628802975953235,0.6286369071343164,0.6285372658429653,0.6282715557326957,0.6287697621894514,0.6284376245516142,0.6283047694964793,0.6280390593862096,0.6282715557326957,0.6282383419689119,0.6282715557326957,0.6281054869137771,0.6281387006775608,0.6280058456224259,0.6281054869137771,0.6278065630397237,0.6278065630397237,0.6278065630397237,0.62777334927594,0.6276737079845888,0.6274412116381028,0.6274412116381028,0.6275740666932377,0.6275740666932377,0.6274744254018866,0.62777334927594,0.6280722731499934,0.6279394180948585,0.6282715557326957,0.6283047694964793,0.6282715557326957,0.6284708383153979,0.6286701208981001,0.6287365484256676,0.6284708383153979,0.628570479606749,0.6285040520791816,0.6284376245516142,0.6284708383153979,0.6284044107878305,0.6282715557326957,0.6282051282051282,0.6283047694964793,0.6282383419689119,0.6280390593862096,0.628337983260263,0.6284044107878305,0.6284708383153979,0.6287697621894514,0.6287033346618839,0.6287365484256676,0.6285040520791816,0.6286369071343164,0.6287697621894514,0.6287033346618839,0.6284376245516142,0.628337983260263,0.6285372658429653,0.6286701208981001,0.6285372658429653,0.628802975953235,0.6287033346618839,0.6289358310083699,0.6288361897170187,0.6288694034808024,0.6287365484256676,0.628570479606749,0.6287365484256676,0.6288361897170187,0.6289358310083699,0.6289026172445862,0.6289690447721535,0.6289358310083699,0.6289358310083699,0.6290686860635047,0.6289026172445862,0.6287365484256676,0.6286036933705328,0.6286701208981001,0.6284044107878305,0.6283711970240468,0.6283047694964793,0.6284708383153979,0.6285040520791816,0.628570479606749,0.6282715557326957,0.6282715557326957,0.6282715557326957,0.6284376245516142,0.6278729905672911,0.6276737079845888,0.6275740666932377,0.6275740666932377,0.6274744254018866,0.6273415703467516,0.6270426464726983,0.627308356582968,0.6268765776537797,0.6266772950710775,0.6266772950710775,0.6267769363624286,0.6264780124883752,0.6264780124883752,0.6267105088348611,0.6269430051813472,0.6269430051813472,0.6268765776537797,0.6270426464726983,0.6274412116381028,0.6272751428191843,0.6269762189451309,0.6273415703467516,0.627075860236482,0.6270094327089146,0.627075860236482,0.627075860236482,0.6271422877640495,0.6271090740002657,0.6272087152916168,0.6271755015278331,0.6269430051813472,0.6271090740002657,0.6267437225986449,0.6266772950710775,0.6267105088348611,0.6267105088348611,0.6266440813072938,0.6267105088348611,0.6268765776537797,0.6271090740002657,0.6269762189451309,0.6271090740002657,0.6267437225986449,0.6266440813072938,0.6267437225986449,0.6269762189451309,0.6268765776537797,0.6268765776537797,0.6268433638899961,0.6268765776537797,0.6270094327089146,0.627075860236482,0.62661086754351,0.6268101501262123,0.6267769363624286,0.6269097914175634,0.6268433638899961,0.6269097914175634,0.6269097914175634,0.6267105088348611,0.6268433638899961,0.6268101501262123,0.6267769363624286,0.6269097914175634,0.6265776537797263,0.6267769363624286,0.6268101501262123,0.6261458748505381,0.625813737212701,0.6257473096851335,0.625913378504052,0.6262455161418892,0.625913378504052,0.6262123023781054,0.6261790886143218,0.6261458748505381,0.6259465922678358,0.6257140959213499,0.626046233559187,0.6261126610867543,0.6267105088348611,0.62661086754351,0.6266772950710775,0.6264115849608077,0.6263119436694566,0.6264780124883752,0.62661086754351,0.6266772950710775,0.6268765776537797,0.6265776537797263,0.6264447987245915,0.6264780124883752,0.6263451574332404,0.6259465922678358,0.6259798060316195,0.6258469509764847,0.6256476683937824,0.6255812408662149,0.6258469509764847,0.6261458748505381,0.6259465922678358,0.6260130197954032,0.6261790886143218,0.6264447987245915,0.6260794473229706,0.6258801647402684,0.6257473096851335,0.6256808821575661,0.6257473096851335,0.6259798060316195,0.625813737212701,0.6258469509764847,0.6260130197954032,0.6259465922678358,0.6258801647402684,0.625913378504052,0.6257805234489172,0.6257805234489172,0.6255480271024313,0.6253819582835127,0.6253155307559453,0.6252491032283778,0.6254815995748638,0.6254151720472964,0.625348744519729,0.6252823169921615,0.6254151720472964,0.625348744519729,0.6251826757008104,0.625348744519729,0.6255148133386476,0.6256808821575661,0.625813737212701,0.6256808821575661,0.6260130197954032,0.6259465922678358,0.6258801647402684,0.6257140959213499,0.6256476683937824,0.6256808821575661,0.6257473096851335,0.6261458748505381,0.625813737212701,0.6259465922678358,0.6257473096851335,0.6257140959213499,0.6261458748505381,0.6261126610867543,0.6262123023781054,0.6262787299056729,0.6265776537797263,0.6261790886143218,0.6262455161418892,0.6262455161418892,0.6259798060316195,0.6261126610867543,0.6262123023781054,0.6262787299056729,0.6262455161418892,0.6259465922678358,0.626046233559187,0.6261126610867543,0.6260794473229706,0.6257473096851335,0.6257805234489172,0.6257473096851335,0.6256144546299987,0.6254815995748638,0.6255480271024313,0.6258469509764847,0.6257805234489172,0.626046233559187,0.6257140959213499,0.6257473096851335,0.625913378504052,0.6260794473229706,0.6262787299056729,0.6262455161418892,0.6267437225986449,0.6267105088348611,0.6266440813072938,0.6268433638899961,0.6267769363624286,0.6269097914175634,0.6271422877640495,0.627075860236482,0.627308356582968,0.6270094327089146,0.6271090740002657,0.6271090740002657,0.6271755015278331,0.6269097914175634,0.6272087152916168,0.6273415703467516,0.6272751428191843,0.6271755015278331,0.6272751428191843,0.6271422877640495,0.6268433638899961,0.6269097914175634,0.6267769363624286,0.6268765776537797,0.6269762189451309,0.6270426464726983,0.6271090740002657,0.6272087152916168,0.6269097914175634,0.6268433638899961,0.6267437225986449,0.6267769363624286,0.6267437225986449,0.6268433638899961,0.6269097914175634,0.6270094327089146,0.627075860236482,0.6272419290554005,0.6271755015278331,0.6271090740002657,0.6272419290554005,0.6273415703467516,0.6273415703467516,0.6272087152916168,0.6268433638899961,0.6268765776537797,0.6269097914175634,0.6268101501262123,0.62661086754351,0.6262455161418892,0.6263451574332404,0.626378371197024,0.6264780124883752,0.6265776537797263,0.6266440813072938,0.62661086754351,0.6265444400159426,0.6264780124883752,0.6267105088348611,0.6268433638899961,0.6267437225986449,0.6268765776537797,0.6271090740002657,0.627075860236482,0.6269762189451309,0.6272751428191843,0.6276404942208051,0.6278065630397237,0.6278729905672911,0.6278397768035073,0.6279062043310748,0.6277401355121562,0.6278729905672911,0.6281054869137771,0.6279726318586423,0.6281387006775608,0.6282051282051282,0.6282383419689119,0.6281054869137771,0.6281387006775608,0.6281719144413445,0.6281719144413445,0.6281719144413445,0.6281387006775608,0.6279394180948585,0.6280058456224259,0.6279726318586423,0.6281054869137771,0.6278397768035073,0.6278729905672911,0.6278729905672911,0.6277069217483725,0.6277069217483725,0.6277069217483725,0.6278397768035073,0.6280058456224259,0.6279062043310748,0.6281054869137771,0.6280390593862096,0.6280722731499934,0.6282051282051282,0.6283711970240468,0.6282383419689119,0.628337983260263,0.6282383419689119,0.6282715557326957,0.628337983260263,0.6285040520791816,0.6285040520791816,0.628570479606749,0.6286036933705328,0.6286369071343164,0.6286369071343164,0.6286369071343164,0.6286369071343164,0.6287697621894514,0.6287697621894514,0.6287033346618839,0.6290022585359373,0.6288361897170187,0.6289690447721535,0.6294008237013419,0.6294340374651255,0.6292347548824233,0.6292015411186396,0.629035472299721,0.6289690447721535,0.6288694034808024,0.6285372658429653,0.6284044107878305,0.6283711970240468,0.6284708383153979,0.6288694034808024,0.629035472299721,0.6289026172445862,0.628802975953235,0.6286701208981001,0.6287365484256676,0.6288361897170187,0.6289358310083699,0.629035472299721,0.629035472299721,0.6288694034808024,0.6289358310083699,0.6289690447721535,0.6290022585359373,0.6290686860635047,0.6290686860635047,0.6291683273548558,0.6291018998272885,0.6292015411186396,0.6291018998272885,0.629035472299721,0.6291018998272885,0.6293343961737744,0.6292015411186396,0.6290686860635047,0.6293011824099907,0.6293343961737744,0.629267968646207,0.629267968646207,0.629267968646207,0.6295336787564767,0.6296001062840441,0.629500464992693,0.6297661751029626,0.6296665338116115,0.6295668925202604,0.6294672512289092,0.6296001062840441,0.6296001062840441,0.6297661751029626,0.6300650989770161,0.6299654576856649,0.6299322439218812,0.6298658163943138,0.6296997475753953,0.6298658163943138,0.6296333200478278,0.6296333200478278,0.6296665338116115,0.6298326026305301,0.6296333200478278,0.6300318852132324],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,11,21,31,41,51,61,71,81,91,101,111,121,131,141,151,161,171,181,191,201,211,221,231,241,251,261,271,281,291,301,311,321,331,341,351,361,371,381,391,401,411,421,431,441,451,461,471,481,491,501,511,521,531,541,551,561,571,581,591,601,611,621,631,641,651,661,671,681,691,701,711,721,731,741,751,761,771,781,791,801,811,821,831,841,851,861,871,881,891,901,911,921,931,941,951,961,971,981,991,1001,1011,1021,1031,1041,1051,1061,1071,1081,1091,1101,1111,1121,1131,1141,1151,1161,1171,1181,1191,1201,1211,1221,1231,1241,1251,1261,1271,1281,1291,1301,1311,1321,1331,1341,1351,1361,1371,1381,1391,1401,1411,1421,1431,1441,1451,1461,1471,1481,1491,1501,1511,1521,1531,1541,1551,1561,1571,1581,1591,1601,1611,1621,1631,1641,1651,1661,1671,1681,1691,1701,1711,1721,1731,1741,1751,1761,1771,1781,1791,1801,1811,1821,1831,1841,1851,1861,1871,1881,1891,1901,1911,1921,1931,1941,1951,1961,1971,1981,1991,2001,2011,2021,2031,2041,2051,2061,2071,2081,2091,2101,2111,2121,2131,2141,2151,2161,2171,2181,2191,2201,2211,2221,2231,2241,2251,2261,2271,2281,2291,2301,2311,2321,2331,2341,2351,2361,2371,2381,2391,2401,2411,2421,2431,2441,2451,2461,2471,2481,2491,2501,2511,2521,2531,2541,2551,2561,2571,2581,2591,2601,2611,2621,2631,2641,2651,2661,2671,2681,2691,2701,2711,2721,2731,2741,2751,2761,2771,2781,2791,2801,2811,2821,2831,2841,2851,2861,2871,2881,2891,2901,2911,2921,2931,2941,2951,2961,2971,2981,2991,3001,3011,3021,3031,3041,3051,3061,3071,3081,3091,3101,3111,3121,3131,3141,3151,3161,3171,3181,3191,3201,3211,3221,3231,3241,3251,3261,3271,3281,3291,3301,3311,3321,3331,3341,3351,3361,3371,3381,3391,3401,3411,3421,3431,3441,3451,3461,3471,3481,3491,3501,3511,3521,3531,3541,3551,3561,3571,3581,3591,3601,3611,3621,3631,3641,3651,3661,3671,3681,3691,3701,3711,3721,3731,3741,3751,3761,3771,3781,3791,3801,3811,3821,3831,3841,3851,3861,3871,3881,3891,3901,3911,3921,3931,3941,3951,3961,3971,3981,3991,4001,4011,4021,4031,4041,4051,4061,4071,4081,4091,4101,4111,4121,4131,4141,4151,4161,4171,4181,4191,4201,4211,4221,4231,4241,4251,4261,4271,4281,4291,4301,4311,4321,4331,4341,4351,4361,4371,4381,4391,4401,4411,4421,4431,4441,4451,4461,4471,4481,4491,4501,4511,4521,4531,4541,4551,4561,4571,4581,4591,4601,4611,4621,4631,4641,4651,4661,4671,4681,4691,4701,4711,4721,4731,4741,4751,4761,4771,4781,4791,4801,4811,4821,4831,4841,4851,4861,4871,4881,4891,4901,4911,4921,4931,4941,4951,4961,4971,4981,4991,5001,5011,5021,5031,5041,5051,5061,5071,5081,5091,5101,5111,5121,5131,5141,5151,5161,5171,5181,5191,5201,5211,5221,5231,5241,5251,5261,5271,5281,5291,5301,5311,5321,5331,5341,5351,5361,5371,5381,5391,5401,5411,5421,5431,5441,5451,5461,5471,5481,5491,5501,5511,5521,5531,5541,5551,5561,5571,5581,5591,5601,5611,5621,5631,5641,5651,5661,5671,5681,5691,5701,5711,5721,5731,5741,5751,5761,5771,5781,5791,5801,5811,5821,5831,5841,5851,5861,5871,5881,5891,5901,5911,5921,5931,5941,5951,5961,5971,5981,5991,6001,6011,6021,6031,6041,6051,6061,6071,6081,6091,6101,6111,6121,6131,6141,6151,6161,6171,6181,6191,6201,6211,6221,6231,6241,6251,6261,6271,6281,6291,6301,6311,6321,6331,6341,6351,6361,6371,6381,6391,6401,6411,6421,6431,6441,6451,6461,6471,6481,6491,6501,6511,6521,6531,6541,6551,6561,6571,6581,6591,6601,6611,6621,6631,6641,6651,6661,6671,6681,6691,6701,6711,6721,6731,6741,6751,6761,6771],\"xaxis\":\"x\",\"y\":[0.6326225587883619,0.6330543377175502,0.6330875514813339,0.6329546964261991,0.6329879101899827,0.6329214826624153,0.6331207652451176,0.6334529028829547,0.6335857579380896,0.6338182542845755,0.634582170851601,0.6342168194499801,0.6337518267570081,0.6332536203002525,0.6333532615916035,0.6331539790089012,0.6334529028829547,0.6330875514813339,0.6332868340640362,0.6337518267570081,0.6335857579380896,0.6330875514813339,0.6329214826624153,0.6324897037332271,0.6328882688986316,0.6328218413710641,0.6326889863159293,0.6323900624418759,0.6324564899694434,0.6324564899694434,0.6326225587883619,0.6323900624418759,0.6326889863159293,0.6328218413710641,0.6325893450245782,0.6323236349143085,0.6327886276072805,0.6327886276072805,0.632722200079713,0.6325561312607945,0.6325561312607945,0.6326889863159293,0.6326557725521456,0.6323568486780922,0.632722200079713,0.6327554138434968,0.6327886276072805,0.6326225587883619,0.6326225587883619,0.6323568486780922,0.6322239936229573,0.6328218413710641,0.6327554138434968,0.6324897037332271,0.6327554138434968,0.6325893450245782,0.6330211239537664,0.6328550551348479,0.6326225587883619,0.6326557725521456,0.6326557725521456,0.6327554138434968,0.6322572073867411,0.63215756609539,0.632024711040255,0.6318918559851202,0.631925069748904,0.6314268632921483,0.6313604357645809,0.6313272220007972,0.631460077055932,0.6313272220007972,0.6312607944732297,0.6320579248040388,0.6322572073867411,0.6322572073867411,0.6323568486780922,0.6319582835126877,0.6315929321110668,0.6318918559851202,0.6312607944732297,0.63099508436296,0.630762588016474,0.6312607944732297,0.6310282981267438,0.6309618705991763,0.6311279394180949,0.6308290155440415,0.6311611531818786,0.6308622293078252,0.6308954430716088,0.6311279394180949,0.631227580709446,0.6314268632921483,0.6316593596386343,0.6316593596386343,0.6313936495283645,0.6311943669456623,0.6310282981267438,0.6306629467251229,0.63099508436296,0.6307293742526903,0.6301647402683672,0.6302643815597183,0.6306629467251229,0.6305633054337717,0.6306297329613392,0.6305965191975554,0.6303308090872858,0.629732961339179,0.6296001062840441,0.6296997475753953,0.6295668925202604,0.6295336787564767,0.629732961339179,0.6298326026305301,0.6298990301580976,0.6296997475753953,0.6296001062840441,0.6296997475753953,0.6297661751029626,0.6295336787564767,0.6296665338116115,0.6296001062840441,0.6297661751029626,0.6296001062840441,0.6296333200478278,0.6298326026305301,0.6295668925202604,0.6296997475753953,0.629732961339179,0.6298990301580976,0.6295668925202604,0.6292015411186396,0.629500464992693,0.629500464992693,0.629267968646207,0.6294672512289092,0.629500464992693,0.6293676099375581,0.6294672512289092,0.6292015411186396,0.6296001062840441,0.6291683273548558,0.6290686860635047,0.6292015411186396,0.6294008237013419,0.629500464992693,0.6293343961737744,0.6294672512289092,0.629500464992693,0.6294672512289092,0.6296333200478278,0.6295668925202604,0.6293343961737744,0.6294672512289092,0.6291351135910721,0.6289690447721535,0.6291351135910721,0.6295336787564767,0.6296665338116115,0.6293343961737744,0.6291018998272885,0.6292015411186396,0.629267968646207,0.6296665338116115,0.6298326026305301,0.6299654576856649,0.6294672512289092,0.629732961339179,0.6302311677959347,0.6295336787564767,0.6296333200478278,0.6294672512289092,0.6295336787564767,0.6296665338116115,0.6295336787564767,0.6294340374651255,0.6293676099375581,0.6293011824099907,0.6296001062840441,0.6294672512289092,0.6296665338116115,0.6298658163943138,0.6297993888667464,0.629267968646207,0.6288361897170187,0.6288694034808024,0.6287697621894514,0.6292015411186396,0.6295668925202604,0.6290022585359373,0.628570479606749,0.6286701208981001,0.6285040520791816,0.628337983260263,0.6282715557326957,0.6285040520791816,0.6287365484256676,0.629035472299721,0.6291351135910721,0.6290686860635047,0.6291018998272885,0.629035472299721,0.6290686860635047,0.629267968646207,0.6291351135910721,0.6291018998272885,0.6287033346618839,0.628570479606749,0.6285372658429653,0.628802975953235,0.6286701208981001,0.6287033346618839,0.6289690447721535,0.6289358310083699,0.6289026172445862,0.6286036933705328,0.628802975953235,0.6286369071343164,0.6288694034808024,0.6291351135910721,0.6292015411186396,0.6290686860635047,0.628570479606749,0.6288694034808024,0.628802975953235,0.6286369071343164,0.6285372658429653,0.6282715557326957,0.6287697621894514,0.6284376245516142,0.6283047694964793,0.6280390593862096,0.6282715557326957,0.6282383419689119,0.6282715557326957,0.6281054869137771,0.6281387006775608,0.6280058456224259,0.6281054869137771,0.6278065630397237,0.6278065630397237,0.6278065630397237,0.62777334927594,0.6276737079845888,0.6274412116381028,0.6274412116381028,0.6275740666932377,0.6275740666932377,0.6274744254018866,0.62777334927594,0.6280722731499934,0.6279394180948585,0.6282715557326957,0.6283047694964793,0.6282715557326957,0.6284708383153979,0.6286701208981001,0.6287365484256676,0.6284708383153979,0.628570479606749,0.6285040520791816,0.6284376245516142,0.6284708383153979,0.6284044107878305,0.6282715557326957,0.6282051282051282,0.6283047694964793,0.6282383419689119,0.6280390593862096,0.628337983260263,0.6284044107878305,0.6284708383153979,0.6287697621894514,0.6287033346618839,0.6287365484256676,0.6285040520791816,0.6286369071343164,0.6287697621894514,0.6287033346618839,0.6284376245516142,0.628337983260263,0.6285372658429653,0.6286701208981001,0.6285372658429653,0.628802975953235,0.6287033346618839,0.6289358310083699,0.6288361897170187,0.6288694034808024,0.6287365484256676,0.628570479606749,0.6287365484256676,0.6288361897170187,0.6289358310083699,0.6289026172445862,0.6289690447721535,0.6289358310083699,0.6289358310083699,0.6290686860635047,0.6289026172445862,0.6287365484256676,0.6286036933705328,0.6286701208981001,0.6284044107878305,0.6283711970240468,0.6283047694964793,0.6284708383153979,0.6285040520791816,0.628570479606749,0.6282715557326957,0.6282715557326957,0.6282715557326957,0.6284376245516142,0.6278729905672911,0.6276737079845888,0.6275740666932377,0.6275740666932377,0.6274744254018866,0.6273415703467516,0.6270426464726983,0.627308356582968,0.6268765776537797,0.6266772950710775,0.6266772950710775,0.6267769363624286,0.6264780124883752,0.6264780124883752,0.6267105088348611,0.6269430051813472,0.6269430051813472,0.6268765776537797,0.6270426464726983,0.6274412116381028,0.6272751428191843,0.6269762189451309,0.6273415703467516,0.627075860236482,0.6270094327089146,0.627075860236482,0.627075860236482,0.6271422877640495,0.6271090740002657,0.6272087152916168,0.6271755015278331,0.6269430051813472,0.6271090740002657,0.6267437225986449,0.6266772950710775,0.6267105088348611,0.6267105088348611,0.6266440813072938,0.6267105088348611,0.6268765776537797,0.6271090740002657,0.6269762189451309,0.6271090740002657,0.6267437225986449,0.6266440813072938,0.6267437225986449,0.6269762189451309,0.6268765776537797,0.6268765776537797,0.6268433638899961,0.6268765776537797,0.6270094327089146,0.627075860236482,0.62661086754351,0.6268101501262123,0.6267769363624286,0.6269097914175634,0.6268433638899961,0.6269097914175634,0.6269097914175634,0.6267105088348611,0.6268433638899961,0.6268101501262123,0.6267769363624286,0.6269097914175634,0.6265776537797263,0.6267769363624286,0.6268101501262123,0.6261458748505381,0.625813737212701,0.6257473096851335,0.625913378504052,0.6262455161418892,0.625913378504052,0.6262123023781054,0.6261790886143218,0.6261458748505381,0.6259465922678358,0.6257140959213499,0.626046233559187,0.6261126610867543,0.6267105088348611,0.62661086754351,0.6266772950710775,0.6264115849608077,0.6263119436694566,0.6264780124883752,0.62661086754351,0.6266772950710775,0.6268765776537797,0.6265776537797263,0.6264447987245915,0.6264780124883752,0.6263451574332404,0.6259465922678358,0.6259798060316195,0.6258469509764847,0.6256476683937824,0.6255812408662149,0.6258469509764847,0.6261458748505381,0.6259465922678358,0.6260130197954032,0.6261790886143218,0.6264447987245915,0.6260794473229706,0.6258801647402684,0.6257473096851335,0.6256808821575661,0.6257473096851335,0.6259798060316195,0.625813737212701,0.6258469509764847,0.6260130197954032,0.6259465922678358,0.6258801647402684,0.625913378504052,0.6257805234489172,0.6257805234489172,0.6255480271024313,0.6253819582835127,0.6253155307559453,0.6252491032283778,0.6254815995748638,0.6254151720472964,0.625348744519729,0.6252823169921615,0.6254151720472964,0.625348744519729,0.6251826757008104,0.625348744519729,0.6255148133386476,0.6256808821575661,0.625813737212701,0.6256808821575661,0.6260130197954032,0.6259465922678358,0.6258801647402684,0.6257140959213499,0.6256476683937824,0.6256808821575661,0.6257473096851335,0.6261458748505381,0.625813737212701,0.6259465922678358,0.6257473096851335,0.6257140959213499,0.6261458748505381,0.6261126610867543,0.6262123023781054,0.6262787299056729,0.6265776537797263,0.6261790886143218,0.6262455161418892,0.6262455161418892,0.6259798060316195,0.6261126610867543,0.6262123023781054,0.6262787299056729,0.6262455161418892,0.6259465922678358,0.626046233559187,0.6261126610867543,0.6260794473229706,0.6257473096851335,0.6257805234489172,0.6257473096851335,0.6256144546299987,0.6254815995748638,0.6255480271024313,0.6258469509764847,0.6257805234489172,0.626046233559187,0.6257140959213499,0.6257473096851335,0.625913378504052,0.6260794473229706,0.6262787299056729,0.6262455161418892,0.6267437225986449,0.6267105088348611,0.6266440813072938,0.6268433638899961,0.6267769363624286,0.6269097914175634,0.6271422877640495,0.627075860236482,0.627308356582968,0.6270094327089146,0.6271090740002657,0.6271090740002657,0.6271755015278331,0.6269097914175634,0.6272087152916168,0.6273415703467516,0.6272751428191843,0.6271755015278331,0.6272751428191843,0.6271422877640495,0.6268433638899961,0.6269097914175634,0.6267769363624286,0.6268765776537797,0.6269762189451309,0.6270426464726983,0.6271090740002657,0.6272087152916168,0.6269097914175634,0.6268433638899961,0.6267437225986449,0.6267769363624286,0.6267437225986449,0.6268433638899961,0.6269097914175634,0.6270094327089146,0.627075860236482,0.6272419290554005,0.6271755015278331,0.6271090740002657,0.6272419290554005,0.6273415703467516,0.6273415703467516,0.6272087152916168,0.6268433638899961,0.6268765776537797,0.6269097914175634,0.6268101501262123,0.62661086754351,0.6262455161418892,0.6263451574332404,0.626378371197024,0.6264780124883752,0.6265776537797263,0.6266440813072938,0.62661086754351,0.6265444400159426,0.6264780124883752,0.6267105088348611,0.6268433638899961,0.6267437225986449,0.6268765776537797,0.6271090740002657,0.627075860236482,0.6269762189451309,0.6272751428191843,0.6276404942208051,0.6278065630397237,0.6278729905672911,0.6278397768035073,0.6279062043310748,0.6277401355121562,0.6278729905672911,0.6281054869137771,0.6279726318586423,0.6281387006775608,0.6282051282051282,0.6282383419689119,0.6281054869137771,0.6281387006775608,0.6281719144413445,0.6281719144413445,0.6281719144413445,0.6281387006775608,0.6279394180948585,0.6280058456224259,0.6279726318586423,0.6281054869137771,0.6278397768035073,0.6278729905672911,0.6278729905672911,0.6277069217483725,0.6277069217483725,0.6277069217483725,0.6278397768035073,0.6280058456224259,0.6279062043310748,0.6281054869137771,0.6280390593862096,0.6280722731499934,0.6282051282051282,0.6283711970240468,0.6282383419689119,0.628337983260263,0.6282383419689119,0.6282715557326957,0.628337983260263,0.6285040520791816,0.6285040520791816,0.628570479606749,0.6286036933705328,0.6286369071343164,0.6286369071343164,0.6286369071343164,0.6286369071343164,0.6287697621894514,0.6287697621894514,0.6287033346618839,0.6290022585359373,0.6288361897170187,0.6289690447721535,0.6294008237013419,0.6294340374651255,0.6292347548824233,0.6292015411186396,0.629035472299721,0.6289690447721535,0.6288694034808024,0.6285372658429653,0.6284044107878305,0.6283711970240468,0.6284708383153979,0.6288694034808024,0.629035472299721,0.6289026172445862,0.628802975953235,0.6286701208981001,0.6287365484256676,0.6288361897170187,0.6289358310083699,0.629035472299721,0.629035472299721,0.6288694034808024,0.6289358310083699,0.6289690447721535,0.6290022585359373,0.6290686860635047,0.6290686860635047,0.6291683273548558,0.6291018998272885,0.6292015411186396,0.6291018998272885,0.629035472299721,0.6291018998272885,0.6293343961737744,0.6292015411186396,0.6290686860635047,0.6293011824099907,0.6293343961737744,0.629267968646207,0.629267968646207,0.629267968646207,0.6295336787564767,0.6296001062840441,0.629500464992693,0.6297661751029626,0.6296665338116115,0.6295668925202604,0.6294672512289092,0.6296001062840441,0.6296001062840441,0.6297661751029626,0.6300650989770161,0.6299654576856649,0.6299322439218812,0.6298658163943138,0.6296997475753953,0.6298658163943138,0.6296333200478278,0.6296333200478278,0.6296665338116115,0.6298326026305301,0.6296333200478278,0.6300318852132324],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"color\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('103ab8be-d62b-49d4-b7d1-c3e708f0fd7b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 101\n",
        "index_to_filter = df_train_.index_id.isin(label_errors_idx_sorted[0:top_k])\n",
        "commend_id_filter = df_train_.loc[index_to_filter,'comment_id']\n",
        "df_train_filtered = df_train_.loc[~df_train_.comment_id.isin(commend_id_filter),:]\n",
        "print(f\"Error frequencies by label for the top_k {top_k}:\", Counter(df_train_.loc[index_to_filter,'sentiment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NClTb1iwwDOb",
        "outputId": "7718fef9-2ee9-4109-ccc5-3dd2873c94cd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error frequencies by label for the top_k 101: Counter({1: 67, 2: 31, 3: 2, 4: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = 10\n",
        "print('\\n')\n",
        "index_to_filter_last = df_train_.index_id.isin(label_errors_idx_sorted[top_k-samples:top_k])\n",
        "print(f\"Loss margin error in top k {samples} samples\")\n",
        "print(df_train_.loc[index_to_filter_last, ['comment_text', 'sentiment', 'predictions_probs']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz1uvTlm0dBO",
        "outputId": "12f772be-cb1f-443a-f223-60c138a16f6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loss margin error in top k 10 samples\n",
            "                                            comment_text  sentiment                                  predictions_probs\n",
            "5026   fuck problem bitch fuck delete dreamtime festi...          2  [0.09691501863761377, 0.8601147391372819, 0.04...\n",
            "6811   general suckitude get cock mouth ban cant beli...          2  [0.8258721323333437, 0.1639007225442004, 0.009...\n",
            "7556   fuck bertie thank taking time make comments re...          1  [0.9065212952448544, 0.08969768834257354, 0.00...\n",
            "9827   wtf place nazi land geezus everything peer rev...          2  [0.8369486423121059, 0.14063907801503797, 0.02...\n",
            "9854   talking little boys like sure utter waste time...          1  [0.9069456908364637, 0.09109598793237296, 0.00...\n",
            "11545  racial jew fool want argue appropriate discuss...          2  [0.8370522457042614, 0.13937722168413127, 0.02...\n",
            "13536  text used proof want sue guys call free encycl...          1  [0.9073338094459872, 0.09147058342833084, 0.00...\n",
            "14174  youve libelled one many done claiming used soc...          1  [0.9055952368577637, 0.08997514626785759, 0.00...\n",
            "14662  reverting reason spent quite time improving ar...          1  [0.9040070579089479, 0.08787620672892645, 0.00...\n",
            "16175  part find false thoroughly disgusted behaviour...          2  [0.8235341601109532, 0.16924862865447685, 0.00...\n"
          ]
        }
      ]
    }
  ]
}