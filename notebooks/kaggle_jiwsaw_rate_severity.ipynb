{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Counter' from 'itertools' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgc\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'Counter' from 'itertools' (unknown location)"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from collections import Counter\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AdamW, AutoTokenizer\n",
    "from scipy.stats import rankdata\n",
    "from sklearn import metrics\n",
    "from models.classifiers import RobertaMultiLabel\n",
    "from parser.datasets import DataSetSeq2SeqMultiLabel\n",
    "from torch_utils.trainer import train_epoch, fit\n",
    "from torch_utils.eval import eval\n",
    "from torch_utils.inference import predict\n",
    "from config import ConfigSeq2SeqMultiLabel\n",
    "from torch_utils.utils import set_seed, get_device, set_cv_dataset_partitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config(ConfigSeq2SeqMultiLabel):\n",
    "  DEVICE = get_device()\n",
    "  # data\n",
    "  LABEL_COLUMNS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "  #TEXT_COLUMN =  'comment_text'\n",
    "  PARITION_COLUMN = 'kfold'\n",
    "  # model\n",
    "  MODEL_NAME = '../input/roberta-base'\n",
    "  MODEL_DROPOUT = 0.2\n",
    "  MODEL_HIDDEN_STATES = 768\n",
    "  MODEL_LABELS = len(LABEL_COLUMNS)\n",
    "  # tokenizer\n",
    "  MAX_LENGTH = 128\n",
    "  # train\n",
    "  TRAIN_BATCH_SIZE = 64 # 32\n",
    "  LEARNING_RATE = 3e-5\n",
    "  EVAL_BATCH_SIZE = 64\n",
    "  TEST_BATCH_SIZE = 64\n",
    "  EPOCHS = 3 # 1\n",
    "  N_FOLDS = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data_loaders(df: pd.DataFrame, df_torch_parser: DataSetSeq2SeqMultiLabel, config:Config,\n",
    "                     tokenizer: AutoTokenizer, kfold: int, text_column: str):\n",
    "\n",
    "    df_torch_test = df_torch_parser(df=df[df[config.PARITION_COLUMN]==kfold],\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  config=config,\n",
    "                                  text_column=text_column)\n",
    "\n",
    "    df_torch_train = df_torch_parser(df=df[df[config.PARITION_COLUMN]!=kfold],\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   config=config,\n",
    "                                   text_column=text_column)\n",
    "\n",
    "    data_loader_train = torch.utils.data.DataLoader(df_torch_train,\n",
    "                                            batch_size=config.TRAIN_BATCH_SIZE,\n",
    "                                            num_workers=2,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            drop_last=False)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(df_torch_test,\n",
    "                                                batch_size=config.TEST_BATCH_SIZE,\n",
    "                                                num_workers=2,\n",
    "                                                shuffle=True,\n",
    "                                                pin_memory=True,\n",
    "                                                drop_last=False)\n",
    "\n",
    "    return data_loader_train, data_loader_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read data\n",
    "df_multi_label = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df_submmit = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "\n",
    "# Assign multi label tags for stratified parition\n",
    "y_tags = [str(y_values) for y_values in  df_multi_label[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values]\n",
    "y_tags_2_idx = dict(Counter(y_tags))\n",
    "df_multi_label['tag_idx'] = [(y_tags_2_idx[y_tag]) for y_tag in y_tags]\n",
    "print(f'dataset size = {len(df_multi_label)}')\n",
    "df_multi_label.head(3)\n",
    "\n",
    "# Perform random under sampling\n",
    "df_multi_label['toxic_score'] = df_multi_label[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "df_multi_label_toxic = df_multi_label.loc[df_multi_label['toxic_score']>0]\n",
    "df_multi_label_non_toxic = df_multi_label.loc[df_multi_label['toxic_score']==0].sample(n=len(df_multi_label_toxic), random_state=41)\n",
    "df_multi_label = pd.concat([df_multi_label_non_toxic, df_multi_label_toxic]).reset_index(drop=True)\n",
    "df_multi_label.toxic_score.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get train components\n",
    "model = RobertaMultiLabel(config=Config)\n",
    "model.to(Config.DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean') # combines Sigmoid layer : MultiLabelSoftMarginLoss\n",
    "optimizer = AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_torch_submmit = DataSetSeq2SeqMultiLabel(df=df_submmit, tokenizer=tokenizer, config=Config, inference_mode=True,\n",
    "                                            text_column='text')\n",
    "\n",
    "data_loader_submmit = torch.utils.data.DataLoader(df_torch_submmit, batch_size=Config.TRAIN_BATCH_SIZE, num_workers=2,\n",
    "                                                  shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "preds_multi_label = pd.DataFrame()\n",
    "\n",
    "# Execute training and inference\n",
    "for kfold in range(Config.N_FOLDS):\n",
    "    # Get data loaders\n",
    "    train_loader, val_loader = get_data_loaders(df=df_multi_label, df_torch_parser=DataSetSeq2SeqMultiLabel,\n",
    "                                                config=Config, tokenizer=tokenizer, kfold=kfold,\n",
    "                                                text_column='comment_text')\n",
    "    # Perform kfold training\n",
    "    best_model, history_log = fit(model=model, optimizer=optimizer, train_loader=train_loader, val_loader=val_loader,\n",
    "                                  loss_fn=loss_fn, device=Config.DEVICE, epochs=Config.EPOCHS,\n",
    "                                  model_path=f'model_multi_{kfold}.bin', scheduler=scheduler)\n",
    "\n",
    "    # PERFORM MODEL PREDICTION\n",
    "    predictions_multilabel = np.array(predict(model=best_model, data_loader=data_loader_submmit, device=Config.DEVICE))\n",
    "    cv_preds = predictions_multilabel.mean(axis=1)\n",
    "    preds_multi_label[f'kfold_{kfold}'] = cv_preds\n",
    "\n",
    "preds_multi_label = preds_multi_label[[f'kfold_{kfold}' for kfold in range(0,Config.N_FOLDS)]].mean(axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL EVALUATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MODEL EVALUATION \"TOXIC CLASSIFICATION\" DATASET\n",
    "class_threshold = 0.3\n",
    "predictions, targets = eval(model=best_model, data_loader=val_loader, device= Config.DEVICE)\n",
    "outputs = np.array(predictions) >= class_threshold\n",
    "print(targets[0:10])\n",
    "print(outputs[0:10])\n",
    "accuracy = metrics.accuracy_score(targets, outputs)\n",
    "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "print(f\"Accuracy Score for toxic classification df = {accuracy}\")\n",
    "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "\n",
    "# PERFORM EVALUATION VAL DATA FROM \"TOXIC RANKING\" DATASET OF LAST CV TRAINED MODEL\n",
    "gc.collect()\n",
    "val_predictions = {}\n",
    "for toxic_column in ['less_toxic', 'more_toxic']:\n",
    "    # PERFORM MODEL PREDICTION\n",
    "    df_torch_val = DataSetSeq2SeqMultiLabel(df=df_val, tokenizer=tokenizer,config=Config, inference_mode=True,\n",
    "                                            text_column=toxic_column)\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(df_torch_val, batch_size=Config.TRAIN_BATCH_SIZE, num_workers=2,\n",
    "                                                  shuffle=True, pin_memory=True, drop_last=False)\n",
    "\n",
    "    predictions_multilabel = np.array(predict(model=best_model, data_loader=data_loader_val, device=Config.DEVICE))\n",
    "    #outputs = np.array(predictions_multilabel) >= class_threshold\n",
    "    preds = predictions_multilabel.mean(axis=1)\n",
    "    val_predictions[toxic_column] = preds\n",
    "\n",
    "metric = np.mean(val_predictions['less_toxic']<val_predictions['more_toxic'])\n",
    "print(f'Accuracy validation data = {metric}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform submission\n",
    "df_submmit['score'] = preds_multi_label\n",
    "df_submmit[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\n",
    "df_submmit['score'] = rankdata(preds_multi_label,  method='ordinal')\n",
    "df_submmit.head(100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a6ed294b",
   "language": "python",
   "display_name": "PyCharm (nlp_tools)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}